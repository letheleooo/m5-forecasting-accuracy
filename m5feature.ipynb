{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "stv = pd.read_hdf('sales_train_validation.h5')\n",
    "cal = pd.read_hdf('calendar.h5')\n",
    "sp = pd.read_hdf('sell_prices.h5')\n",
    "# create a list for date column names\n",
    "d_cols = ['d_' + str(i) for i in range(1, 1914)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data in dtypes using less memory\n",
    "cal['wm_yr_wk'] = cal['wm_yr_wk'].astype('int16')\n",
    "cal[['wday', 'month']] = cal[['wday', 'month']].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for sales record\n",
    "stv.index = stv['id'].apply(lambda x: x[:-11])\n",
    "sales_by_depts = stv[d_cols+['dept_id', 'id']].groupby('dept_id')\n",
    "temp = sales_by_depts.get_group('HOBBIES_1')\n",
    "temp = temp.drop(['dept_id', 'id'], axis=1).T\n",
    "temp['date'] = pd.to_datetime(cal['date'][:1913].values, format='%Y-%m-%d')\n",
    "# add Walmart year and week infomation\n",
    "temp['wm_yr_wk'] = cal['wm_yr_wk'][:1913].values\n",
    "# add holiday information\n",
    "temp['event'] = cal['event_name_1'][:1913].values\n",
    "temp['event'] = temp['event'].replace('nan', 0)\n",
    "indices = temp['event'][temp['event']!=0].index\n",
    "temp['event'].loc[indices] = list(range(1, 155))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt down the dataframe while keeping the date, wm_yr_wk\n",
    "# and event label for each item\n",
    "df_sales = pd.melt(temp, id_vars=['date', 'wm_yr_wk', 'event'])\n",
    "df_sales.rename(columns={'value': 'sales'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for price record\n",
    "sp['dept_id'] = sp['item_id'].apply(lambda x: x[:-4])\n",
    "sp['id'] = sp['item_id'] + '_' + sp['store_id']\n",
    "sp = sp.drop(['store_id', 'item_id'], axis=1)\n",
    "sp['wm_yr_wk'] = sp['wm_yr_wk'].astype('int16')\n",
    "prices_by_depts = sp.groupby('dept_id')\n",
    "df_prices = prices_by_depts.get_group('HOBBIES_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some data to save memory\n",
    "del temp; del stv; del sp; del cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate sales and price dataframes\n",
    "# make the index unique\n",
    "df_sales.index = df_sales['wm_yr_wk'].astype('str') + '_'  + df_sales['id']\n",
    "df_prices.index = df_prices['wm_yr_wk'].astype('str') + '_'  + df_prices['id']\n",
    "df_sales['sell_price'] = df_prices['sell_price']\n",
    "# fill the null with 0\n",
    "df_sales['sell_price'].fillna(value=0, inplace=True)\n",
    "# reset index\n",
    "df_sales.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add day of the month information\n",
    "df_sales['day_of_month'] = df_sales['date'].dt.day\n",
    "# add day of the week information\n",
    "df_sales['day_of_week'] = df_sales['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete useless data to save memory\n",
    "del df_prices\n",
    "df_sales.drop('wm_yr_wk', inplace=True, axis=1)\n",
    "# reindex and drop useless columns\n",
    "df_sales.index = df_sales['date']\n",
    "df_sales.drop('date', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers\n",
    "def find_outliers(series):\n",
    "    outliers = (series - series.mean()) > 1.96 * series.std()\n",
    "    return outliers\n",
    "# replace the outliers with the maximum of normal values\n",
    "def cap_values(series):\n",
    "    outliers = find_outliers(series)\n",
    "    maximum = series[~outliers].max()\n",
    "    series[outliers] = maximum\n",
    "    return series\n",
    "\n",
    "# group the data by items' id and iterate over each item\n",
    "items = df_sales.groupby('id')\n",
    "df_sales['is_outlier'] = items.apply(lambda x: find_outliers(x['sales'])).values.ravel()\n",
    "df_sales['sales_capped'] = items.apply(lambda x: cap_values(x['sales'])).values.ravel()\n",
    "# return the natural logrithm of 1 plus the input array\n",
    "df_sales['sales_log1p'] = np.log1p(df_sales['sales'])\n",
    "df_sales['sales_capped_log1p'] = np.log1p(df_sales['sales_capped']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# a function to show the process\n",
    "# feel free to annotate it if it's unecessary for you\n",
    "items_count = len(items)\n",
    "def counter(func):\n",
    "    temp = [int(items_count*i*0.1) for i in range(1, 11)]\n",
    "    def wrapper(data, on):\n",
    "        wrapper.count += 1\n",
    "        if wrapper.count in temp:\n",
    "            print(f'processing:{wrapper.count/items_count*100}%')\n",
    "        return func(data, on)\n",
    "    wrapper.count = 0\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @counter\n",
    "def ex_stats(data, on):\n",
    "    # create a dict to collect all the stats\n",
    "    stats = {'mean':[], 'std':[], 'median':[], 'max':[], 'min':[]}\n",
    "    # iterate over groups and calculate precedent statistics\n",
    "    alphas = [0.1, 0.25, 0.3, 0.5, 0.75, 1]\n",
    "    stats.update({f'exp_{alpha}_mean':[] for alpha in alphas})\n",
    "    # create groupby object\n",
    "    shift = data[on].shift()\n",
    "    roll = shift.expanding()\n",
    "    stats['mean'].extend(roll.mean())\n",
    "    stats['std'].extend(roll.std())\n",
    "    stats['median'].extend(roll.median())\n",
    "    stats['max'].extend(roll.max())\n",
    "    stats['min'].extend(roll.min())\n",
    "    # calulate ewm series with different alphas    \n",
    "    for alpha in alphas:\n",
    "        exp_roll = shift.ewm(alpha=alpha, adjust=False)\n",
    "        stats[f'exp_{alpha}_mean'].extend(exp_roll.mean())\n",
    "    for keys, values in stats.items():\n",
    "        data[f'{on}_{keys}'] = values\n",
    "    return data\n",
    "# applying ex_stats to each item\n",
    "df_sales = items.apply(lambda x: ex_stats(data=x, on='sales'))\n",
    "items = df_sales.groupby('id')\n",
    "df_sales = items.apply(lambda x: ex_stats(x, on='sales_capped'))\n",
    "items = df_sales.groupby('id')\n",
    "df_sales = items.apply(lambda x: ex_stats(x, on='sales_capped_log1p'))\n",
    "# drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>sales_capped</th>\n",
       "      <th>sales_log1p</th>\n",
       "      <th>sales_capped_log1p</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_capped_log1p_std</th>\n",
       "      <th>sales_capped_log1p_median</th>\n",
       "      <th>sales_capped_log1p_max</th>\n",
       "      <th>sales_capped_log1p_min</th>\n",
       "      <th>sales_capped_log1p_exp_0.1_mean</th>\n",
       "      <th>sales_capped_log1p_exp_0.25_mean</th>\n",
       "      <th>sales_capped_log1p_exp_0.3_mean</th>\n",
       "      <th>sales_capped_log1p_exp_0.5_mean</th>\n",
       "      <th>sales_capped_log1p_exp_0.75_mean</th>\n",
       "      <th>sales_capped_log1p_exp_1_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30</th>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           event                  id  sales  sell_price  day_of_month  \\\n",
       "date                                                                    \n",
       "2011-01-29     0  HOBBIES_1_001_CA_1      0         0.0            29   \n",
       "2011-01-30     0  HOBBIES_1_001_CA_1      0         0.0            30   \n",
       "2011-01-31     0  HOBBIES_1_001_CA_1      0         0.0            31   \n",
       "2011-02-01     0  HOBBIES_1_001_CA_1      0         0.0             1   \n",
       "2011-02-02     0  HOBBIES_1_001_CA_1      0         0.0             2   \n",
       "\n",
       "            day_of_week  is_outlier  sales_capped  sales_log1p  \\\n",
       "date                                                             \n",
       "2011-01-29            5       False             0          0.0   \n",
       "2011-01-30            6       False             0          0.0   \n",
       "2011-01-31            0       False             0          0.0   \n",
       "2011-02-01            1       False             0          0.0   \n",
       "2011-02-02            2       False             0          0.0   \n",
       "\n",
       "            sales_capped_log1p  ...  sales_capped_log1p_std  \\\n",
       "date                            ...                           \n",
       "2011-01-29                 0.0  ...                     NaN   \n",
       "2011-01-30                 0.0  ...                     NaN   \n",
       "2011-01-31                 0.0  ...                     0.0   \n",
       "2011-02-01                 0.0  ...                     0.0   \n",
       "2011-02-02                 0.0  ...                     0.0   \n",
       "\n",
       "            sales_capped_log1p_median  sales_capped_log1p_max  \\\n",
       "date                                                            \n",
       "2011-01-29                        NaN                     NaN   \n",
       "2011-01-30                        0.0                     0.0   \n",
       "2011-01-31                        0.0                     0.0   \n",
       "2011-02-01                        0.0                     0.0   \n",
       "2011-02-02                        0.0                     0.0   \n",
       "\n",
       "            sales_capped_log1p_min  sales_capped_log1p_exp_0.1_mean  \\\n",
       "date                                                                  \n",
       "2011-01-29                     NaN                              NaN   \n",
       "2011-01-30                     0.0                              0.0   \n",
       "2011-01-31                     0.0                              0.0   \n",
       "2011-02-01                     0.0                              0.0   \n",
       "2011-02-02                     0.0                              0.0   \n",
       "\n",
       "            sales_capped_log1p_exp_0.25_mean  sales_capped_log1p_exp_0.3_mean  \\\n",
       "date                                                                            \n",
       "2011-01-29                               NaN                              NaN   \n",
       "2011-01-30                               0.0                              0.0   \n",
       "2011-01-31                               0.0                              0.0   \n",
       "2011-02-01                               0.0                              0.0   \n",
       "2011-02-02                               0.0                              0.0   \n",
       "\n",
       "            sales_capped_log1p_exp_0.5_mean  sales_capped_log1p_exp_0.75_mean  \\\n",
       "date                                                                            \n",
       "2011-01-29                              NaN                               NaN   \n",
       "2011-01-30                              0.0                               0.0   \n",
       "2011-01-31                              0.0                               0.0   \n",
       "2011-02-01                              0.0                               0.0   \n",
       "2011-02-02                              0.0                               0.0   \n",
       "\n",
       "            sales_capped_log1p_exp_1_mean  \n",
       "date                                       \n",
       "2011-01-29                            NaN  \n",
       "2011-01-30                            0.0  \n",
       "2011-01-31                            0.0  \n",
       "2011-02-01                            0.0  \n",
       "2011-02-02                            0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['items_id'] = df_sales['id'].str.slice(0, 13)\n",
    "df_sales['store_id'] = df_sales['id'].str.slice(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['id', 'is_outlier', 'sales_capped', 'sales_capped_log1p']\n",
    "df_sales = df_sales.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\pandas\\core\\generic.py:2490: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->integer,key->block0_values] [items->Index(['event'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "# save the file\n",
    "df_sales.to_hdf('HOBBIES_1.h5', key='df', mode='w', format='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# extract time series information\n",
    "from scipy import optimize\n",
    "\n",
    "# define a function to get the exponential weighted moving average series\n",
    "def calc_shifted_ewm(series, alpha, adjust=True):\n",
    "    # move the values to the next day\n",
    "    # adjust == True means using weights (1-a)^2 \n",
    "    return series.shift().ewm(alpha=alpha, adjust=adjust).mean()\n",
    "\n",
    "## define an optimization function to select the best alpha\n",
    "def find_best_signal(series, adjust=False, eps=10e-5):\n",
    "    \n",
    "    def find(alpha):\n",
    "        # make sure that alpha is between 0 and 1\n",
    "        shifted_ewm = calc_shifted_ewm(series=series, alpha=min(max(alpha, 0), 1), \n",
    "                                       adjust=adjust)\n",
    "        # define a loss function\n",
    "        loss = np.mean(np.power(series - shifted_ewm, 2))\n",
    "        return loss\n",
    "    \n",
    "    # find the global minimum of the function\n",
    "    # get the optimal alpha and pass it to ewm calculation function\n",
    "    res = optimize.differential_evolution(func=find, bounds=[(0+eps, 1-eps)])\n",
    "    best_alpha = res['x'][0]\n",
    "    return calc_shifted_ewm(series=series, alpha=best_alpha, adjust=adjust)\n",
    "2\n",
    "# iterate over items and add ewmed sales series\n",
    "groups = df_sales.groupby(['id', 'day_of_week'])\n",
    "roll_sales_capped = groups.apply(lambda x: find_best_signal(x['sales_capped']))\n",
    "df_sales['optimiazed_ewm_by_id_&_day_of_week'] = roll_sales_capped.values.ravel()\n",
    "roll_sales_capped_log1p = groups.apply(lambda x: find_best_signal(x['sales_capped_log1p']))\n",
    "df_sales['optimiazed_ewm_log1p_by_id_&_day_of_week'] = roll_sales_capped_log1p.values.ravel()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
